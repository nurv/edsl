{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4656a990-03ca-4cc1-b233-8d6cfa331fc3",
   "metadata": {},
   "source": [
    "# Using EDSL for concept induction\n",
    "This notebook shows how [EDSL](https://docs.expectedparrot.com) can be used to perform a \"concept induction\" on some unstructured text. In a series of steps we use EDSL to create some simple methods for:\n",
    "\n",
    "* Synthesizing topics from a set of unstructured texts\n",
    "* Creating criteria for determining whether a text addresses a given topic\n",
    "* Scoring how well each text satisfies each criteria\n",
    "\n",
    "This example is inspired by Michelle Lam & team's fascinating recent work on concept induction: \"Analyzing Unstructured Text with High-Level Concepts Using LLooM\" (https://twitter.com/michelle123lam/status/1781031027567390749).\n",
    "\n",
    "<i>[EDSL](https://docs.expectedparrot.com) is an open-source Python package for conducting surveys and experiments with language models. Please see our docs for details on [getting started](https://docs.expectedparrot.com/en/latest/starter_tutorial.html).</i>\n",
    "\n",
    "## Extending the analysis\n",
    "These methods can easily be modified to perform a different analysis by editing the <i>question_text</i> instructions for the language model. The analysis can also be extended to compare results using any of the [available models for EDSL](https://docs.expectedparrot.com/en/latest/language_models.html), and to examine how results change when different AI agent personas are used to conduct the analysis (e.g., we can create agents with personas relevant to the review that we prompt the language model to reference in conducting the analysis--please see details on [creating AI agents](https://docs.expectedparrot.com/en/latest/agents.html) in our docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a999785-7636-4c35-9978-1c35147bd62e",
   "metadata": {},
   "source": [
    "### Importing the tools\n",
    "EDSL comes with a variety of standard question types (see examples of all [question types](https://docs.expectedparrot.com/en/latest/questions.html#question-type-classes)). Here we import the ones that we want to use based on the desired form of the response. `QuestionList` will format the response as a list of strings, `QuestionFreeText` will return unstructured text and `QuestionNumerical` will return a numerical value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0511bd3-ccac-4eaa-a795-6c7bf7c30784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionList, QuestionFreeText, QuestionNumerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08df141c-8a6a-406c-8247-a654323ce96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of topics addressed in a piece of text\n",
    "def get_topics(text):\n",
    "    q = QuestionList(\n",
    "        question_name = \"topics\",\n",
    "        question_text = f\"\"\"Return a list of topics addressed in the following text: {text}\"\"\"\n",
    "    )\n",
    "    results = q.run().select(\"topics\").to_list()[0]\n",
    "    return results\n",
    "\n",
    "# Condense a list of topics\n",
    "def condense_topics(topics):\n",
    "    q = QuestionList(\n",
    "        question_name = \"condense\",\n",
    "        question_text = f\"\"\"Return a condensed non-duplicative list of the following topics: {topics}\"\"\"\n",
    "    )\n",
    "    results = q.run().select(\"condense\").to_list()[0]\n",
    "    return results\n",
    "\n",
    "# Create criteria for a given topic\n",
    "def get_criteria(topic):\n",
    "    q = QuestionFreeText(\n",
    "        question_name = \"criteria\",\n",
    "        question_text = f\"\"\"Consider the following topic: {topic}. \n",
    "        Briefly describe some criteria for determining whether a given text addresses this topic.\"\"\"\n",
    "    )\n",
    "    results = q.run().select(\"criteria\").to_list()[0]\n",
    "    return results\n",
    "\n",
    "# Score how well a text satisfies the criteria for a topic\n",
    "def get_score(topic, criteria, text):\n",
    "    q = QuestionNumerical(\n",
    "        question_name = \"score\",\n",
    "        question_text = f\"\"\"Consider the following topic and criteria for determining whether a given text addresses the topic:\n",
    "        Topic: {topic}\n",
    "        Criteria: {criteria}\n",
    "        On a scale from 0 to 100, how well does the following text satisfy these criteria such that we are confidant \n",
    "        that the text addresses the topic? (0 = Not at all, 100 = Perfectly)\n",
    "        Text: {text}\"\"\"\n",
    "    )\n",
    "    results = q.run().select(\"score\").to_list()[0]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b23741-3386-4ddd-a532-cad3b623105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the methods for a set of texts\n",
    "\n",
    "texts = [\n",
    "    \"Sean Duffy. Honestly, I'm disgusted by these remarks! Democrats are mad at Biden, but for the wrong reason! I thought we were better than this but apparently, we're not there yet...\",\n",
    "    \"Senator Chuck Schumer. It's been incredible to meet with so many New Yorkers today as we celebrate #MLKDay and as we work to honor the life and legacy of Reverend Dr. Martin Luther King, Jr. by continuing his march toward equality for all.\",\n",
    "    \"U.S. Senator Elizabeth Warren. House Republicans want to impose a national sales tax, while giving more tax breaks to the rich. The result? Higher costs for working families on everything from gas to groceries. It's outrageous.\",\n",
    "    \"Ron Johnson. Congrats Ronna McDaniel. Looking forward to your continued leadership.\",\n",
    "    \"Senator Michael Bennet. The fatal beating of Tyre Nichols is horrifying. I'm devastated for his family and the Memphis community. We must fight for a world that ends this injustice and inhumane brutality at last.\",\n",
    "    \"Kyrsten Sinema. 'Close to 80% of the graduates are women and people of color, fulfilling a key diversity marker the airline aimed to achieve.' This is awesome - sending a warm congraulations to this talented class of future pilots! 'United Aviate Academy in Arizona graduates its 1st class of future pilots. Why that's big.'\",\n",
    "    \"Senator Chuck Schumer. Today, we mark international Holocaust Remembrance Day. We will never forget the 6 million Jewish victims and other victims of the Nazis. And on a day when innocent victims are murdered in a terror attack in a Jerusalem synagogue, we must continue to fight antisemitism and hatred.\"\n",
    "]\n",
    "\n",
    "def analyze_texts(texts):\n",
    "    topics = []\n",
    "    for text in texts:\n",
    "        topics.append(get_topics(text))\n",
    "\n",
    "    condensed_topics = condense_topics(topics)\n",
    "\n",
    "    topics_criteria = {}\n",
    "    for topic in condensed_topics:\n",
    "        topics_criteria[topic] = get_criteria(topic)\n",
    "\n",
    "    analyzed_texts = []\n",
    "    for text in texts:\n",
    "        topics_scores = {}\n",
    "        topics_scores[\"text\"] = text\n",
    "        for topic, criteria in topics_criteria.items():\n",
    "            topics_scores[topic] = get_score(topic, criteria, text)\n",
    "        analyzed_texts.append(topics_scores)\n",
    "\n",
    "    return analyzed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b7130-673b-4368-9df9-4cea599ce1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2575e3d-3df6-4ac1-a2a9-87f4b93b061a",
   "metadata": {},
   "source": [
    "### Using AI agents\n",
    "This analysis can be extended by comparing results for different personas that we prompt the language model to reference in answering the questions. This is done by passing a dictionary of desired traits to an `Agent` object. For example, we could create an agent representing a political strategist to answer the questions in the above methods as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed42a09-3b3b-4574-b253-cb7ac5be322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"myTable\" class=\"display\">\n",
       "  <thead>\n",
       "  <tr>\n",
       "    <th>agent.persona</th>\n",
       "    <th>answer.important_topics</th>\n",
       "  </tr>\n",
       "  </thead>\n",
       "</tbody>\n",
       "  <tr>\n",
       "    <td>You are a political strategist...</td>\n",
       "    <td>The important topics in the texts include criticism of President Biden by members of his own party, the celebration and continuation of Dr. Martin Luther King Jr.'s legacy, opposition to a proposed national sales tax and its impact on working families, leadership within the Republican party, the call for justice and an end to police brutality following the death of Tyre Nichols, the achievement of diversity goals in a pilot training academy, and the commemoration of International Holocaust Remembrance Day coupled with a denunciation of a recent terror attack and a call to fight antisemitism and hatred.</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an Agent with some traits\n",
    "from edsl import Agent\n",
    "\n",
    "agent = Agent(name = \"Political strategist\", traits = {\"persona\": \"You are a political strategist...\"}) \n",
    "\n",
    "q = QuestionFreeText(\n",
    "    question_name = \"important_topics\",\n",
    "    question_text = \"What are the most important topics in the following texts: {{ texts }}\"\n",
    ")\n",
    "\n",
    "# We can use Scenario objects to parameterize questions\n",
    "from edsl import Scenario\n",
    "\n",
    "scenario = Scenario({\"texts\": texts})\n",
    "\n",
    "# Run the question with the specified agent\n",
    "results = q.by(scenario).by(agent).run()\n",
    "\n",
    "# Inspect results\n",
    "results.select(\"persona\", \"important_topics\").print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5000f-feb8-4b2d-9b05-3da1e185c841",
   "metadata": {},
   "source": [
    "Learn more about creating AI agents to use with surveys [here](https://docs.expectedparrot.com/en/latest/agents.html). Learn more about working with survey results [here](https://docs.expectedparrot.com/en/latest/results.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904a455-bcbe-4b8c-866a-967bcf4a5499",
   "metadata": {},
   "source": [
    "### Selecting language models\n",
    "In the methods above we did not specify a language model, so the default model, GPT 4, was used to generate results. To compare results using different language models, we create `Model` objects for desired models and modify the methods to use those models.\n",
    "\n",
    "To see currently available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8117fb70-bef7-43db-b8ef-b6d6ac62b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claude-3-haiku-20240307',\n",
       " 'claude-3-opus-20240229',\n",
       " 'claude-3-sonnet-20240229',\n",
       " 'dbrx-instruct',\n",
       " 'gemini_pro',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4-1106-preview',\n",
       " 'llama-2-13b-chat-hf',\n",
       " 'llama-2-70b-chat-hf',\n",
       " 'mixtral-8x7B-instruct-v0.1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "Model.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260fb1b4-b5f4-49be-8f9c-e3e833eebc6b",
   "metadata": {},
   "source": [
    "To specify a model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737afbe8-e4a1-41b9-add1-ea42d1062230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdfb69-012a-48eb-b274-a4e18ea641d7",
   "metadata": {},
   "source": [
    "To run a question or survey with a specified model we append the `by` method as we do for scenarios and agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50b6024-a810-46a7-989e-f13204336454",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = q.by(scenario).by(agent).by(model).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e2f9-a6ef-4675-8b00-eec732cf378c",
   "metadata": {},
   "source": [
    "Learn more about specifying models to use with surveys [here](https://docs.expectedparrot.com/en/latest/language_models.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
